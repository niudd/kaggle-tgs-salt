{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of trainset:  500\n",
      "Count of validset:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warm_start: checkpoint/seed1234-hypercol/best.pth.tar\n",
      "[EPOCH 00000][mask coverage not zero] train_loss, train_iou: 1.17407, 0.67417; val_loss, val_iou: 0.99600, 0.68925\n",
      "[EPOCH 00001][mask coverage not zero] train_loss, train_iou: 1.50108, 0.57823; val_loss, val_iou: 0.62608, 0.81640\n",
      "[EPOCH 00002][mask coverage not zero] train_loss, train_iou: 0.87182, 0.72927; val_loss, val_iou: 0.57377, 0.83312\n",
      "[EPOCH 00003][mask coverage not zero] train_loss, train_iou: 0.86372, 0.71056; val_loss, val_iou: 2.49209, 0.30000\n",
      "[EPOCH 00004][mask coverage not zero] train_loss, train_iou: 0.90462, 0.71628; val_loss, val_iou: 0.99647, 0.64615\n",
      "[EPOCH 00005][mask coverage not zero] train_loss, train_iou: 0.95383, 0.70729; val_loss, val_iou: 0.84309, 0.71134\n",
      "[EPOCH 00006][mask coverage not zero] train_loss, train_iou: 0.92862, 0.71162; val_loss, val_iou: 0.69165, 0.77748\n",
      "Process Process-282:\n",
      "Process Process-300:\n",
      "Process Process-297:\n",
      "Process Process-286:\n",
      "Process Process-299:\n",
      "Process Process-298:\n",
      "Traceback (most recent call last):\n",
      "Process Process-285:\n",
      "Process Process-292:\n",
      "Process Process-294:\n",
      "Traceback (most recent call last):\n",
      "Process Process-296:\n",
      "Process Process-283:\n",
      "Process Process-293:\n",
      "Process Process-284:\n",
      "Process Process-281:\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process Process-295:\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-288:\n",
      "Process Process-287:\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Process Process-290:\n",
      "Process Process-291:\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "Process Process-289:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/endi/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-295e8106874e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m \u001b[0mrun_check_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-295e8106874e>\u001b[0m in \u001b[0;36mrun_check_net\u001b[0;34m(train_dl, val_dl)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0m_train_loss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#_train_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m#train_loss = np.mean(train_loss_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from model import UNetResNet34\n",
    "from model2 import UNetResNet34\n",
    "#from my_model import UNetResNet34\n",
    "from metrics import iou_pytorch\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from dataset import TgsDataSet\n",
    "\n",
    "\n",
    "######### Load TGS salt data #########\n",
    "def prepare_data():\n",
    "    # read numpy format data\n",
    "    with open('../data/processed/dataset_%d.pkl'%SEED, 'rb') as f:\n",
    "        ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = pickle.load(f)\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_valid = y_valid.astype(np.uint8)\n",
    "    if debug:\n",
    "        x_train, y_train = x_train[:500], y_train[:500]\n",
    "        x_valid, y_valid = x_valid[:100], y_valid[:100]\n",
    "    print('Count of trainset: ', x_train.shape[0])\n",
    "    print('Count of validset: ', x_valid.shape[0])\n",
    "\n",
    "    # make pytorch.data.Dataset\n",
    "    train_ds = TgsDataSet(x_train, y_train)\n",
    "    val_ds = TgsDataSet(x_valid, y_valid)\n",
    "    \n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        #sampler=StratifiedSampler(),\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    \n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        #sampler=StratifiedSampler(),\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    \n",
    "    return train_dl, val_dl\n",
    "\n",
    "######### Run the training process #########\n",
    "def run_check_net(train_dl, val_dl):\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #---\n",
    "    net = UNetResNet34(pretrained=True).cuda(device=device)#debug=False\n",
    "#     for param in net.named_parameters():\n",
    "#         if param[0][:8] in ['decoder5']:#'decoder5', 'decoder4', 'decoder3', 'decoder2'\n",
    "#             param[1].requires_grad = False\n",
    "    #net = SaltLinkNet(num_classes=1, dropout_2d=0.0, pretrained=True, is_deconv=False).cuda(device=device)\n",
    "\n",
    "    # dummy sgd to see if it can converge ...\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                      lr=LearningRate, momentum=0.9, weight_decay=0.0001)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "    #                                                       factor=0.5, patience=6, \n",
    "    #                                                       verbose=False, threshold=0.0001, \n",
    "    #                                                       threshold_mode='rel', cooldown=0, \n",
    "    #                                                       min_lr=0, eps=1e-08)\n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "\n",
    "    diff = 0\n",
    "    best_val_iou = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        # iterate through trainset\n",
    "        net.set_mode('train')\n",
    "        train_loss_list0, train_iou_list0 = [], []\n",
    "        train_loss_list1, train_iou_list1 = [], []\n",
    "        #train_loss_list, train_iou_list = [], []\n",
    "        for input_data, truth in train_dl:\n",
    "            #set_trace()\n",
    "            input_data, truth = input_data.to(device=device, dtype=torch.float), truth.to(device=device, dtype=torch.float)\n",
    "            logit = net(input_data)\n",
    "            \n",
    "            # calculate metrics separately on data with zero_mask_coverage and nonzero_mask_coverage\n",
    "            is_zero_cov = (truth.sum(dim=2, keepdim=False).sum(dim=2, keepdim=False)==0).reshape(-1)#.type(torch.FloatTensor)\n",
    "            if (is_zero_cov==1).all():\n",
    "                continue\n",
    "            #logit_zero_cov = logit[is_zero_cov, ]\n",
    "            #truth_zero_cov = truth[is_zero_cov, ]\n",
    "            logit_nonzero_cov = logit[1 - is_zero_cov, ]\n",
    "            truth_nonzero_cov = truth[1 - is_zero_cov, ]\n",
    "            \n",
    "            _train_loss1 = net.criterion(logit_nonzero_cov, truth_nonzero_cov)\n",
    "            _train_iou1 = net.metric(logit_nonzero_cov, truth_nonzero_cov)\n",
    "            #train_loss_list0.append(_train_loss0.detach())\n",
    "            #train_iou_list0.append(_train_iou0.detach())\n",
    "            train_loss_list1.append(_train_loss1.detach())\n",
    "            train_iou_list1.append(_train_iou1.detach())\n",
    "            \n",
    "            #_train_loss  = net.criterion(logit, truth)\n",
    "            #_train_iou  = net.metric(logit, truth)\n",
    "            #train_loss_list.append(_train_loss.detach())\n",
    "            #train_iou_list.append(_train_iou.detach())\n",
    "            \n",
    "            _train_loss1.backward()#_train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #train_loss = np.mean(train_loss_list)\n",
    "        #train_iou = np.mean(train_iou_list)\n",
    "        #train_loss0, train_iou0 = np.mean(train_loss_list0), np.mean(train_iou_list0)\n",
    "        train_loss1, train_iou1 = np.mean(train_loss_list1), np.mean(train_iou_list1)\n",
    "                \n",
    "        # compute valid loss & iou (for memory efficiency, use batch)\n",
    "        net.set_mode('valid')\n",
    "        with torch.no_grad():\n",
    "            #val_loss_list, val_iou_list = [], []\n",
    "            val_loss_list0, val_loss_list1 = [], []\n",
    "            val_iou_list0, val_iou_list1 = [], []\n",
    "            for input_data, truth in val_dl:\n",
    "                input_data, truth = input_data.to(device=device, dtype=torch.float), truth.to(device=device, dtype=torch.float)\n",
    "                logit = net(input_data)\n",
    "                \n",
    "                # calculate metrics separately on data with zero_mask_coverage and nonzero_mask_coverage\n",
    "                is_zero_cov = (truth.sum(dim=2, keepdim=False).sum(dim=2, keepdim=False)==0).reshape(-1)#.type(torch.FloatTensor)\n",
    "                if (is_zero_cov==1).all():\n",
    "                    continue\n",
    "                #logit_zero_cov = logit[is_zero_cov, ]\n",
    "                #truth_zero_cov = truth[is_zero_cov, ]\n",
    "                logit_nonzero_cov = logit[1 - is_zero_cov, ]\n",
    "                truth_nonzero_cov = truth[1 - is_zero_cov, ]\n",
    "                \n",
    "                _val_loss1 = net.criterion(logit_nonzero_cov, truth_nonzero_cov)\n",
    "                _val_iou1 = net.metric(logit_nonzero_cov, truth_nonzero_cov)\n",
    "                #val_loss_list0.append(_val_loss0.detach())\n",
    "                #val_iou_list0.append(_val_iou0.detach())\n",
    "                val_loss_list1.append(_val_loss1.detach())\n",
    "                val_iou_list1.append(_val_iou1.detach())\n",
    "                \n",
    "                #_val_loss = net.criterion(logit, truth)\n",
    "                #_val_iou = net.metric(logit, truth)\n",
    "                #val_loss_list.append(_val_loss)\n",
    "                #val_iou_list.append(_val_iou)\n",
    "            #val_loss = np.mean(val_loss_list)\n",
    "            #val_iou = np.mean(val_iou_list)\n",
    "            #val_loss0, val_iou0 = np.mean(val_loss_list0), np.mean(val_iou_list0)\n",
    "            val_loss1, val_iou1 = np.mean(val_loss_list1), np.mean(val_iou_list1)\n",
    "\n",
    "        # Adjust learning_rate\n",
    "        #scheduler.step(val_iou1)\n",
    "        #\n",
    "        if val_iou1 > best_val_iou:\n",
    "            best_val_iou = val_iou1\n",
    "            is_best = True\n",
    "            diff = 0\n",
    "        else:\n",
    "            is_best = False\n",
    "            diff += 1\n",
    "            if diff > early_stopping_round:\n",
    "                logging.info('Early Stopping: val_iou does not increase %d rounds'%early_stopping_round)\n",
    "                #print('Early Stopping: val_iou does not increase %d rounds'%early_stopping_round)\n",
    "                break\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            #'metrics': {'train_loss': train_loss, 'val_loss': val_loss, 'train_iou': train_iou, 'val_iou': val_iou}\n",
    "            'metrics': {'train_loss1': train_loss1, \n",
    "                        'val_loss1': val_loss1, \n",
    "                        'train_iou1': train_iou1, \n",
    "                        'val_iou1': val_iou1}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "\n",
    "        #if i%20==0:\n",
    "        if i>-1:\n",
    "            #logging.info('[EPOCH %05d][mask coverage zero] train_loss, train_iou: %0.5f, %0.5f; val_loss, val_iou: %0.5f, %0.5f'%(i, train_loss0.item(), train_iou0.item(), val_loss0.item(), val_iou0.item()))\n",
    "            logging.info('[EPOCH %05d][mask coverage not zero] train_loss, train_iou: %0.5f, %0.5f; val_loss, val_iou: %0.5f, %0.5f'%(i, train_loss1.item(), train_iou1.item(), val_loss1.item(), val_iou1.item()))\n",
    "            #logging.info('[EPOCH %05d] train_loss, train_iou: %0.5f,%0.5f; val_loss, val_iou: %0.5f,%0.5f'%(i, train_loss.item(), train_iou.item(), val_loss.item(), val_iou.item()))\n",
    "        i = i+1\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"#\"0, 1, 2, 3, 4, 5\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "#torch.set_num_threads(20)\n",
    "\n",
    "SEED = 1234\n",
    "debug = True# if True, load 100 samples\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 20\n",
    "warm_start, last_checkpoint_path = True, 'checkpoint/seed1234-hypercol/best.pth.tar'\n",
    "checkpoint_path = 'checkpoint/seed%d-hypercol-phase2'%SEED#seed%d-phase2, seed%d ;;; seed%d-hypercol, seed%d-hypercol-phase2\n",
    "LOG_PATH = 'logging/seed%d-hypercol.log'%SEED#seed%d.log\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "NUM_EPOCHS = 200#500\n",
    "early_stopping_round = 500#30\n",
    "LearningRate = 0.0001#0.001\n",
    "\n",
    "train_dl, val_dl = prepare_data()\n",
    "\n",
    "run_check_net(train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
